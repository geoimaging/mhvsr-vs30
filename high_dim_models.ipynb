{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45fb0c14-1b87-4180-ab73-b07ad49dde1a",
   "metadata": {},
   "source": [
    "# Estimation of the Vs30 (m/s) with the mHVSR using high-dimensional models.\n",
    "\n",
    "## Information\n",
    "This file is a free software as a part of: \n",
    ">{citation}.\n",
    "\n",
    "Copyright (C) 2025 Kushal Sharma Wagle (wagleyk@vt.edu).\n",
    "\n",
    "\n",
    "## Citation\n",
    "\n",
    "If you use _hvsrpy_ in your research or consulting, we ask you please cite the following:\n",
    "\n",
    ">Joseph Vantassel. (2020). jpvantassel/hvsrpy: latest (Concept). Zenodo.\n",
    "[http://doi.org/10.5281/zenodo.3666956](http://doi.org/10.5281/zenodo.3666956)\n",
    "\n",
    "\n",
    ">Vantassel, J.P. (2025). hvsrpy: An Open‐Source Python Package for Microtremor and Earthquake Horizontal‐to‐Vertical Spectral Ratio Processing. Seismological Research Letters 2025. [https://doi.org/10.1785/0220240395].\n",
    "\n",
    "_Note: For software, version specific citations should be preferred to\n",
    "general concept citations, such as that listed above. To generate a version\n",
    "specific citation for hvsrpy, please use the citation tool on the hvsrpy\n",
    "[archive](http://doi.org/10.5281/zenodo.3666956)._\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "This notebook illustrates how mHVSR can be leveraged to estimate the Vs30 for the site. The processing has been done following the SESAME (2004) guidelines.\n",
    "If you use this notebook, please also cite SESAME (2004) to recognize their original work.\n",
    "\n",
    "> SESAME (2004). Guidelines for the Implementation of the H/V Spectral Ratio Technique on Ambient Vibrations\n",
    "> Measurements, Processing, and Interpretation. European Commission - Research General Directorate, 62,\n",
    "> European Commission - Research General Directorate.\n",
    "\n",
    "To use this notebook, you need a three-component microtremor recording with at least 30 minutes of recording with a broadband sensor of at least 100Hz sampling rate.\n",
    "\n",
    "This notebook predicts Vs30 with two separate models: Single mode ANN and Dual Mode ANN. Foe Single mode ANN, just the microtremor recording is sufficient (as mentioned above). However, for the Dual mode ANN, you need topographic features: elevation and average elevation around 1500m diameter of the station. These must be computed using 1 arcsec Digital Elevation Model (DEM) to remain consistent with the model development. If you don't have these data, you can use another notebook and use the model \"Single mode ANN\" with just the microtremor recording.\n",
    "\n",
    "Steps to use:\n",
    "1. Simply, download the zipped folder with the name \"Models Public\", and do not change the files structure in it.\n",
    "2. Input all the required parameters, input recording (full or relative path is fine) and topographic features in the input section.\n",
    "3. Restart Kernel and run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2cba5-6d18-4a3e-82ab-8ee2824ff419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import hvsrpy\n",
    "from hvsrpy import sesame\n",
    "import obspy\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import joblib\n",
    "\n",
    "plt.style.use(hvsrpy.postprocessing.HVSRPY_MPL_STYLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96887ae-0243-4bdf-a7ce-7cdc94b84145",
   "metadata": {},
   "source": [
    "### Data Input and Recording Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abd95a-02cc-48f9-ab01-a8ecc3199d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Input\n",
    "input_recording = \"CI.FUR-Rec288-Sen450.mseed\"  #Actual elevation = -44m and elevation_1500m_avg = -43.80603662m.\n",
    "# input_recording = \"AR.STN01.A1.2019.006\"  #Actual elevation = 2246m and elevation_1500m_avg = 2237.903656m.\n",
    "# input_recording = \"UT.STN09_20130320_020000.miniseed\" #Actual elevation = 35m and elevation_1500m_avg = 35.33800078m.\n",
    "elevation = 2246  #in meters. Enter \"NA\" if unknown.\n",
    "elevation_1500m_avg = 2237.903656  # in meters. Enter \"NA\" if unknown.\n",
    "\n",
    "stream = obspy.read(input_recording)\n",
    "\n",
    "# Check trace count\n",
    "if len(stream) != 3:\n",
    "    print(\"Recording should have exactly three traces.\")\n",
    "else:\n",
    "    # Check sampling rates\n",
    "    sampling_rates = [tr.stats.sampling_rate for tr in stream]\n",
    "    if any(sr < 100 for sr in sampling_rates):\n",
    "        print(\"At least 100 Hz sampling rate is required. Found rates:\", sampling_rates)\n",
    "    else:\n",
    "        # Find latest start time and earliest end time\n",
    "        start_times = [tr.stats.starttime for tr in stream]\n",
    "        end_times = [tr.stats.endtime for tr in stream]\n",
    "\n",
    "        common_start = max(start_times)\n",
    "        common_end = min(end_times)\n",
    "\n",
    "        # Check duration\n",
    "        common_duration = common_end - common_start\n",
    "        if common_duration <= 0:\n",
    "            print(\"No overlapping time window between traces.\")\n",
    "        else:\n",
    "            # Trim all traces to common time window\n",
    "            stream.trim(starttime=common_start, endtime=common_end)\n",
    "\n",
    "            # Save to MiniSEED file\n",
    "            stream.write(f\"updated_{input_recording}\", format=\"MSEED\")\n",
    "\n",
    "            # Check if duration exceeds 30 minutes\n",
    "            if common_duration >= 1800:  # 1800 seconds = 30 minutes\n",
    "                print(f\"Trimmed duration is {common_duration/60:.2f} minutes.\")\n",
    "            else:\n",
    "                print(\"Trimmed duration is less than 30 minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198aa980-0eca-4344-ad09-abf5a552b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVSR Preprocessing Settings\n",
    "preprocessing_settings = hvsrpy.settings.HvsrPreProcessingSettings()\n",
    "preprocessing_settings.detrend = \"linear\"\n",
    "significant_cycles = 15  # require 15 significant cycles.\n",
    "time_windows = 35  # require 35 time windows.\n",
    "duration_in_seconds = common_duration  # window length (s)\n",
    "windowlength_in_seconds = duration_in_seconds / time_windows\n",
    "preprocessing_settings.window_length_in_seconds = windowlength_in_seconds\n",
    "\n",
    "print(\"Preprocessing Summary\")\n",
    "print(\"-\"*60)\n",
    "preprocessing_settings.psummary()\n",
    "\n",
    "# HVSR Processing Settings\n",
    "processing_settings = hvsrpy.settings.HvsrTraditionalProcessingSettings()\n",
    "processing_settings.window_type_and_width = (\"tukey\", 0.2)\n",
    "processing_settings.smoothing=dict(operator=\"konno_and_ohmachi\",\n",
    "                                   bandwidth=40,\n",
    "                                   center_frequencies_in_hz=np.geomspace(0.05, 50, 256))\n",
    "processing_settings.method_to_combine_horizontals = \"geometric_mean\"\n",
    "processing_settings.handle_dissimilar_time_steps_by = \"frequency_domain_resampling\"\n",
    "\n",
    "desired_frequency_vector_in_hz = np.geomspace(0.05, 50, 256)\n",
    "minimum_frequency = significant_cycles / windowlength_in_seconds\n",
    "fids = desired_frequency_vector_in_hz > minimum_frequency\n",
    "frequency_resampling_in_hz = desired_frequency_vector_in_hz[fids]\n",
    "processing_settings.smoothing[\"center_frequencies_in_hz\"] = frequency_resampling_in_hz\n",
    "\n",
    "print(\"Processing Summary\")\n",
    "print(\"-\"*60)\n",
    "processing_settings.psummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f38bf2-82f2-465d-b57f-6c07b192c31f",
   "metadata": {},
   "source": [
    "### HVSR Processing and Manual Window Rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c6bd22-127f-4bf8-900c-7861ba547a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute HVSR\n",
    "\n",
    "srecords = hvsrpy.read([f\"updated_{input_recording}\"])\n",
    "srecords = hvsrpy.preprocess(srecords, preprocessing_settings)\n",
    "hvsr = hvsrpy.process(srecords, processing_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2a816-2082-40a0-b600-cc8bf27df9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HvsrTraditional object\n",
    "mhvsr = hvsrpy.HvsrTraditional(frequency=hvsr.frequency, amplitude=hvsr.amplitude)\n",
    "\n",
    "# Perform manual window rejection\n",
    "hvsrpy.window_rejection.manual_window_rejection(\n",
    "    mhvsr, y_limit=15, plot_frequency_std=False, fig=None, ax=None  #Change y_limit as required in the plot.\n",
    ")\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6d274-f36e-4004-89b5-5fbf7382853f",
   "metadata": {},
   "source": [
    "### Parameters for high dim model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac0256-9667-4028-af28-53ac6d0ee7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVSR Features\n",
    "# Original frequency and amplitude arrays\n",
    "freqs = mhvsr.frequency  # original frequency array\n",
    "amps = mhvsr.mean_curve(distribution=\"lognormal\")  #Taking the lognormal mean curve among the accepted windows.\n",
    "\n",
    "# Step 1: Trim to 0.3–50 Hz range\n",
    "mask = (freqs >= 0.3) & (freqs <= 50)\n",
    "freqs_trimmed = freqs[mask]\n",
    "amps_trimmed = amps[mask]\n",
    "\n",
    "# Step 2: Create 35 log-spaced frequencies between 0.3 and 50 Hz\n",
    "resampled_freqs = np.logspace(np.log10(0.3), np.log10(50), 35)\n",
    "\n",
    "# Step 3: Interpolate amplitudes linearly\n",
    "interp_func = interp1d(freqs_trimmed, amps_trimmed, kind='linear', bounds_error=False, fill_value=\"extrapolate\")\n",
    "resampled_amps = interp_func(resampled_freqs)\n",
    "\n",
    "X_hvsr = pd.DataFrame([resampled_amps], columns=[f for f in resampled_freqs])\n",
    "\n",
    "if elevation!=\"NA\" and elevation_1500m_avg!=\"NA\":\n",
    "    dual_ANN = True\n",
    "    # Topographic Features\n",
    "    elevation = elevation\n",
    "    TPI = elevation - elevation_1500m_avg\n",
    "    \n",
    "    # Assemble into DataFrame\n",
    "    X_topo = pd.DataFrame([{\n",
    "        \"TPI\": TPI,\n",
    "        \"elevation\": elevation\n",
    "    }])\n",
    "    \n",
    "    # Elevation Binning\n",
    "    elevation_bins = [-500, 0, 500, 1000, 1500, 2000, 2500, 3000]\n",
    "    elevation_labels = [\n",
    "        'Elevation_Bin_[-500.0, 0.0)',\n",
    "        'Elevation_Bin_[0.0, 500.0)',\n",
    "        'Elevation_Bin_[500.0, 1000.0)',\n",
    "        'Elevation_Bin_[1000.0, 1500.0)',\n",
    "        'Elevation_Bin_[1500.0, 2000.0)',\n",
    "        'Elevation_Bin_[2000.0, 2500.0)',\n",
    "        'Elevation_Bin_[2500.0, 3000.0)'\n",
    "    ]\n",
    "    \n",
    "    # Bin the elevation into categories\n",
    "    X_topo = X_topo.copy()\n",
    "    X_topo['Elevation_Bin'] = pd.cut(X_topo['elevation'], bins=elevation_bins, labels=elevation_labels, right=False)\n",
    "    \n",
    "    # One-hot encode the elevation bin\n",
    "    elevation_dummies = pd.get_dummies(X_topo['Elevation_Bin']).astype(int)\n",
    "    \n",
    "    # Concatenate back to original DataFrame\n",
    "    X_topo = pd.concat([X_topo, elevation_dummies], axis=1)\n",
    "    \n",
    "    # Optional: Drop 'Elevation_Bin' column if you only need one-hot encoded version\n",
    "    X_topo = X_topo.drop(columns=['elevation','Elevation_Bin'])\n",
    "else:\n",
    "    dual_ANN = False\n",
    "    print(\"Only Single mode ANN model can be used.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5ac4a-3119-486a-ab8c-49bdecfa409d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbbe86-e334-4d8f-b6ba-5a7df4b314b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hvsr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427265a-a8c3-493c-8336-38fa0c8ae877",
   "metadata": {},
   "source": [
    "### Load high-dimensional models and Scale Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69292a4-f4f3-410d-a6ae-8aebd1223325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models\n",
    "\n",
    "single_mode_ann_model = tf.keras.models.load_model(\"../Models Public/Models/log_ANN_model.keras\")\n",
    "X_hvsr_scaled = np.log(X_hvsr.to_numpy().astype(np.float32)) \n",
    "\n",
    "if dual_ANN:\n",
    "    dual_mode_ann_model = tf.keras.models.load_model(\"../Models Public/Models/Multi-input_log_ANN.keras\")\n",
    "    topo_scaler = joblib.load(\"../Models Public/Models/log_model_standard_scaler_metadata.pkl\")\n",
    "    X_topo_scaled = topo_scaler.transform(X_topo.to_numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf8244-2133-4e86-8e6c-90eb704c72b4",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772a59a-80cd-48d7-bf64-56f0387b7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always predict with single mode\n",
    "Vs30_pred_single_ann = single_mode_ann_model.predict(X_hvsr_scaled).flatten()\n",
    "\n",
    "models = [\"Single Mode ANN\"]\n",
    "predictions = [np.exp(Vs30_pred_single_ann)]\n",
    "\n",
    "# If topo features are available.\n",
    "if dual_ANN:\n",
    "    Vs30_pred_dual_ann = dual_mode_ann_model.predict([X_hvsr_scaled, X_topo_scaled]).flatten()\n",
    "    models.append(\"Dual mode ANN\")\n",
    "    predictions.append(np.exp(Vs30_pred_dual_ann))\n",
    "\n",
    "# Create DataFrame\n",
    "vs30_modelwise_df = pd.DataFrame({\n",
    "    \"Model\": np.repeat(models, [len(p) for p in predictions]),\n",
    "    \"Vs30 (m/s)\": np.round(np.concatenate(predictions), 0).astype(int)\n",
    "})\n",
    "\n",
    "# Show the result\n",
    "vs30_modelwise_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
