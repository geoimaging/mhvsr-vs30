{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71723193-0d87-4bdc-ab6a-f21df8f621e4",
   "metadata": {},
   "source": [
    "# Estimation of the Vs30 (m/s) with the mHVSR using low-dimensional models.\n",
    "\n",
    "## Information\n",
    "This file is a free software as a part of:\n",
    ">{citation}.\n",
    "\n",
    "Copyright (C) 2025 Kushal Sharma Wagle (wagleyk@vt.edu).\n",
    "\n",
    "\n",
    "## Citation\n",
    "\n",
    "If you use _hvsrpy_ in your research or consulting, we ask you please cite the following:\n",
    "\n",
    ">Joseph Vantassel. (2020). jpvantassel/hvsrpy: latest (Concept). Zenodo.\n",
    "[http://doi.org/10.5281/zenodo.3666956](http://doi.org/10.5281/zenodo.3666956)\n",
    "\n",
    "\n",
    ">Vantassel, J.P. (2025). hvsrpy: An Open‐Source Python Package for Microtremor and Earthquake Horizontal‐to‐Vertical Spectral Ratio Processing. Seismological Research Letters 2025. [https://doi.org/10.1785/0220240395].\n",
    "\n",
    "_Note: For software, version specific citations should be preferred to\n",
    "general concept citations, such as that listed above. To generate a version\n",
    "specific citation for hvsrpy, please use the citation tool on the hvsrpy\n",
    "[archive](http://doi.org/10.5281/zenodo.3666956)._\n",
    "\n",
    "## About this notebook\n",
    "\n",
    "This notebook illustrates how mHVSR can be leveraged to estimate the Vs30 for the site. The processing has been done following the SESAME (2004) guidelines.\n",
    "If you use this notebook, please also cite SESAME (2004) to recognize their original work.\n",
    "\n",
    "> SESAME (2004). Guidelines for the Implementation of the H/V Spectral Ratio Technique on Ambient Vibrations\n",
    "> Measurements, Processing, and Interpretation. European Commission - Research General Directorate, 62,\n",
    "> European Commission - Research General Directorate.\n",
    "\n",
    "To use this notebook, you need at least one clear resonance peak in the mHVSR curve. For more information regarding the clear resonance peak, see the SESAME (2004) guidelines. Also, with this notebook, if the clarity criteria FAILS, it is not recommended to proceed further with the prediction.\n",
    "\n",
    "\n",
    "Additionally, you need topographic features: elevation and average elevation around 1500m diameter of the station. These shall be computed using 1 arcsec Digital Elevation Model (DEM) to remain consistent with the model development. If you don't have these data, you can use another notebook and use the model \"Single mode ANN\" with just the microtremor recording.\n",
    "\n",
    "Steps to use:\n",
    "1. Simply, download the zipped folder with the name \"Models Public\", and do not change the files structure in it.\n",
    "2. Input all the required parameters, input recording (full or relative path is fine) and topographic features in the input section.\n",
    "3. Restart Kernel and run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad2cba5-6d18-4a3e-82ab-8ee2824ff419",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import hvsrpy\n",
    "from hvsrpy import sesame\n",
    "import obspy\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "import joblib\n",
    "\n",
    "plt.style.use(hvsrpy.postprocessing.HVSRPY_MPL_STYLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96887ae-0243-4bdf-a7ce-7cdc94b84145",
   "metadata": {},
   "source": [
    "### Data Input and Recording Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92abd95a-02cc-48f9-ab01-a8ecc3199d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Input\n",
    "# input_recording = \"CI.FUR-Rec288-Sen450.mseed\"  #Actual elevation = -44m and elevation_1500m_avg = -43.80603662m.\n",
    "input_recording = \"AR.STN01.A1.2019.006\"  #Actual elevation = 2246m and elevation_1500m_avg = 2237.903656m.\n",
    "# input_recording = \"UT.STN09_20130320_020000.miniseed\" #Actual elevation = 35m and elevation_1500m_avg = 35.33800078m.\n",
    "elevation =  2246 #in meters.\n",
    "elevation_1500m_avg =  2237.903656 # in meters.\n",
    "\n",
    "\n",
    "stream = obspy.read(input_recording)\n",
    "\n",
    "# Check trace count\n",
    "if len(stream) != 3:\n",
    "    print(\"Recording should have exactly three traces.\")\n",
    "else:\n",
    "    # Find latest start time and earliest end time\n",
    "    start_times = [tr.stats.starttime for tr in stream]\n",
    "    end_times = [tr.stats.endtime for tr in stream]\n",
    "\n",
    "    common_start = max(start_times)\n",
    "    common_end = min(end_times)\n",
    "\n",
    "    # Check duration\n",
    "    common_duration = common_end - common_start\n",
    "    if common_duration <= 0:\n",
    "        print(\"No overlapping time window between traces.\")\n",
    "    else:\n",
    "        # Trim all traces to common time window\n",
    "        stream.trim(starttime=common_start, endtime=common_end)\n",
    "\n",
    "        # Save to MiniSEED file\n",
    "        stream.write(f\"updated_{input_recording}\", format=\"MSEED\")\n",
    "\n",
    "        # Check if duration exceeds 30 minutes\n",
    "        if common_duration >= 1800:  # 1800 seconds = 30 minutes\n",
    "            print(f\"Trimmed duration is {common_duration/60 :.2f} minutes.\")\n",
    "        else:\n",
    "            print(\"Trimmed duration is less than 30 minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198aa980-0eca-4344-ad09-abf5a552b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HVSR Preprocessing Settings\n",
    "preprocessing_settings = hvsrpy.settings.HvsrPreProcessingSettings()\n",
    "preprocessing_settings.detrend = \"linear\"\n",
    "significant_cycles = 15  # require 15 significant cycles.\n",
    "time_windows = 35  # require 35 time windows.\n",
    "duration_in_seconds = common_duration  # window length (s)\n",
    "windowlength_in_seconds = duration_in_seconds / time_windows\n",
    "preprocessing_settings.window_length_in_seconds = windowlength_in_seconds\n",
    "\n",
    "print(\"Preprocessing Summary\")\n",
    "print(\"-\"*60)\n",
    "preprocessing_settings.psummary()\n",
    "\n",
    "# HVSR Processing Settings\n",
    "processing_settings = hvsrpy.settings.HvsrTraditionalProcessingSettings()\n",
    "processing_settings.window_type_and_width = (\"tukey\", 0.2)\n",
    "processing_settings.smoothing=dict(operator=\"konno_and_ohmachi\",\n",
    "                                   bandwidth=40,\n",
    "                                   center_frequencies_in_hz=np.geomspace(0.05, 50, 256))\n",
    "processing_settings.method_to_combine_horizontals = \"geometric_mean\"\n",
    "processing_settings.handle_dissimilar_time_steps_by = \"frequency_domain_resampling\"\n",
    "\n",
    "desired_frequency_vector_in_hz = np.geomspace(0.05, 50, 256)\n",
    "minimum_frequency = significant_cycles / windowlength_in_seconds\n",
    "fids = desired_frequency_vector_in_hz > minimum_frequency\n",
    "frequency_resampling_in_hz = desired_frequency_vector_in_hz[fids]\n",
    "processing_settings.smoothing[\"center_frequencies_in_hz\"] = frequency_resampling_in_hz\n",
    "\n",
    "print(\"Processing Summary\")\n",
    "print(\"-\"*60)\n",
    "processing_settings.psummary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f38bf2-82f2-465d-b57f-6c07b192c31f",
   "metadata": {},
   "source": [
    "### HVSR Processing and Manual Window Rejection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c6bd22-127f-4bf8-900c-7861ba547a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute HVSR\n",
    "\n",
    "srecords = hvsrpy.read([f\"updated_{input_recording}\"])\n",
    "srecords = hvsrpy.preprocess(srecords, preprocessing_settings)\n",
    "hvsr = hvsrpy.process(srecords, processing_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2a816-2082-40a0-b600-cc8bf27df9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HvsrTraditional object\n",
    "mhvsr = hvsrpy.HvsrTraditional(frequency=hvsr.frequency, amplitude=hvsr.amplitude)\n",
    "\n",
    "# Perform manual window rejection\n",
    "hvsrpy.window_rejection.manual_window_rejection(\n",
    "    mhvsr, y_limit=15, plot_frequency_std=False, fig=None, ax=None  #Change y_limit as required in the plot.\n",
    ")\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607493d-7375-46d6-8988-9b5a6cf99795",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_range_in_hz = (None, None)\n",
    "verbose = 1\n",
    "\n",
    "print(\"\\nSESAME (2004) Clarity and Reliability Criteria:\")\n",
    "print(\"-\"*47)\n",
    "hvsrpy.sesame.reliability(\n",
    "    windowlength=preprocessing_settings.window_length_in_seconds,\n",
    "    passing_window_count=np.sum(mhvsr.valid_window_boolean_mask),\n",
    "    frequency=mhvsr.frequency,\n",
    "    mean_curve=mhvsr.mean_curve(distribution=\"lognormal\"),\n",
    "    std_curve=mhvsr.std_curve(distribution=\"lognormal\"),\n",
    "    search_range_in_hz=search_range_in_hz,\n",
    "    verbose=verbose,\n",
    ")\n",
    "hvsrpy.sesame.clarity(\n",
    "    frequency=mhvsr.frequency,\n",
    "    mean_curve=mhvsr.mean_curve(distribution=\"lognormal\"),\n",
    "    std_curve=mhvsr.std_curve(distribution=\"lognormal\"),\n",
    "    fn_std=mhvsr.std_fn_frequency(distribution=\"normal\"),\n",
    "    search_range_in_hz=search_range_in_hz,\n",
    "    verbose=verbose,\n",
    ")\n",
    "\n",
    "fig, axs = hvsrpy.plot_single_panel_hvsr_curves(mhvsr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf6d274-f36e-4004-89b5-5fbf7382853f",
   "metadata": {},
   "source": [
    "### Parameters for low dim model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac0256-9667-4028-af28-53ac6d0ee7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_mean = mhvsr.mean_fn_frequency(distribution=\"lognormal\")\n",
    "an_mean = mhvsr.mean_fn_amplitude(distribution=\"lognormal\")\n",
    "elevation = elevation\n",
    "TPI = elevation - elevation_1500m_avg\n",
    "\n",
    "# Function to compute skewness ignoring leading NaNs and filtering to 0.2–50 Hz\n",
    "def compute_skew_ignore_leading_nans(freqs, amps):\n",
    "    # Filter by frequency range\n",
    "    mask = (freqs > 0.199) & (freqs < 50)\n",
    "    filtered_amps = amps[mask]\n",
    "\n",
    "    # Ignore leading NaNs\n",
    "    first_valid_index = np.argmax(~np.isnan(filtered_amps))\n",
    "    trimmed = filtered_amps[first_valid_index:]\n",
    "    valid = trimmed[~np.isnan(trimmed)]\n",
    "\n",
    "    return skew(valid, bias=False) if len(valid) >= 3 else np.nan\n",
    "\n",
    "\n",
    "mhvsr_mean_curve = mhvsr.mean_curve(distribution=\"lognormal\")  #Taking the lognormal mean curve among the accepted windows.\n",
    "skewness = compute_skew_ignore_leading_nans(mhvsr.frequency, mhvsr_mean_curve)\n",
    "\n",
    "# Assemble into DataFrame\n",
    "X = pd.DataFrame([{\n",
    "    \"fn_mean\": fn_mean,\n",
    "    \"an_mean\": an_mean,\n",
    "    \"TPI\": TPI,\n",
    "    \"Skewness\": skewness,\n",
    "    \"elevation\": elevation\n",
    "}])\n",
    "\n",
    "# Elevation Binning\n",
    "elevation_bins = [-500, 0, 500, 1000, 1500, 2000, 2500, 3000]\n",
    "elevation_labels = [\n",
    "    'Elevation_Bin_[-500.0, 0.0)',\n",
    "    'Elevation_Bin_[0.0, 500.0)',\n",
    "    'Elevation_Bin_[500.0, 1000.0)',\n",
    "    'Elevation_Bin_[1000.0, 1500.0)',\n",
    "    'Elevation_Bin_[1500.0, 2000.0)',\n",
    "    'Elevation_Bin_[2000.0, 2500.0)',\n",
    "    'Elevation_Bin_[2500.0, 3000.0)'\n",
    "]\n",
    "\n",
    "# Bin the elevation into categories\n",
    "X = X.copy()\n",
    "X['Elevation_Bin'] = pd.cut(X['elevation'], bins=elevation_bins, labels=elevation_labels, right=False)\n",
    "\n",
    "# One-hot encode the elevation bin\n",
    "elevation_dummies = pd.get_dummies(X['Elevation_Bin']).astype(int)\n",
    "\n",
    "# Concatenate back to original DataFrame\n",
    "X = pd.concat([X, elevation_dummies], axis=1)\n",
    "\n",
    "# Optional: Drop 'Elevation_Bin' column if you only need one-hot encoded version\n",
    "X = X.drop(columns=['elevation','Elevation_Bin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cbbe86-e334-4d8f-b6ba-5a7df4b314b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d427265a-a8c3-493c-8336-38fa0c8ae877",
   "metadata": {},
   "source": [
    "### Load low-dimensional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69292a4-f4f3-410d-a6ae-8aebd1223325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models\n",
    "\n",
    "linear_model = joblib.load(\"../Models Public/Models/linear_model.joblib\")\n",
    "decisiontree_model = joblib.load(\"../Models Public/Models/decision_tree_model.joblib\")\n",
    "randomforest_model = joblib.load(\"../Models Public/Models/random_forest_model.joblib\")\n",
    "xgboost_model = joblib.load(\"../Models Public/Models/xgboost_model.joblib\")\n",
    "\n",
    "# Feature Scaling for linear model\n",
    "X_linear = X.copy().to_numpy()\n",
    "\n",
    "boxcox_scaler = joblib.load(\"../Models Public/Models/linear_f0hvsr_scaler.pkl\") # fn_mean: Box-Cox Transform\n",
    "X_linear[:, 0] = boxcox_scaler.transform(X_linear[:, 0].reshape(-1, 1)).flatten()\n",
    "\n",
    "X_linear[:, 1] = np.log(X_linear[:, 1]) #an_mean: log transformation\n",
    "\n",
    "std_scaler_tpi = joblib.load(\"../Models Public/Models/linear_topo_scaler.pkl\") #TPI: Standard transformation\n",
    "X_linear[:, 2] = std_scaler_tpi.transform(X_linear[:, 2].reshape(-1, 1)).flatten()\n",
    "\n",
    "std_scaler_skew = joblib.load(\"../Models Public/Models/linear_skewness_scaler.pkl\") #Skewness: standard transformation\n",
    "X_linear[:, 3] = std_scaler_tpi.transform(X_linear[:, 3].reshape(-1, 1)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf8244-2133-4e86-8e6c-90eb704c72b4",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7772a59a-80cd-48d7-bf64-56f0387b7525",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs30_pred_linear = linear_model.predict(X_linear)\n",
    "Vs30_pred_decisiontree = decisiontree_model.predict(X.to_numpy())\n",
    "Vs30_pred_randomforest = randomforest_model.predict(X.to_numpy())\n",
    "Vs30_pred_xgboost = xgboost_model.predict(X.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ead1b-77cf-496b-b798-051a6e3e809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack predictions and model labels\n",
    "models = [\"Linear\", \"Decision Tree\", \"Random Forest\", \"XGBoost\"]\n",
    "predictions = [\n",
    "    np.exp(Vs30_pred_linear),\n",
    "    np.exp(Vs30_pred_decisiontree),\n",
    "    np.exp(Vs30_pred_randomforest),\n",
    "    np.exp(Vs30_pred_xgboost)\n",
    "]\n",
    "\n",
    "# Create dataframe\n",
    "# Create dataframe with 0 decimal precision\n",
    "vs30_modelwise_df = pd.DataFrame({\n",
    "    \"Model\": np.repeat(models, [len(p) for p in predictions]),\n",
    "    \"Vs30 (m/s)\": np.round(np.concatenate(predictions), 0).astype(int)\n",
    "})\n",
    "\n",
    "#Show Results\n",
    "vs30_modelwise_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
